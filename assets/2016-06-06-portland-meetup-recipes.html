<!DOCTYPE html>
<html>
  <head>
    <base target="_blank">
    <title>Open source recipes to build, ship and run production apps with Docker</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }

      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
        margin-top: 0.5em;
      }
      a {
        text-decoration: none;
        color: blue;
      }
      .remark-slide-content { padding: 1em 2.5em 1em 2.5em; }

      .remark-slide-content { font-size: 25px; }
      .remark-slide-content h1 { font-size: 50px; }
      .remark-slide-content h2 { font-size: 50px; }
      .remark-slide-content h3 { font-size: 25px; }
      .remark-code { font-size: 25px; }
      .small .remark-code { font-size: 16px; }

      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .red { color: #fa0000; }
      .gray { color: #ccc; }
      .small { font-size: 70%; }
      .big { font-size: 140%; }
      .underline { text-decoration: underline; }
      .pic {
        vertical-align: middle;
        text-align: center;
        padding: 0 0 0 0 !important;
      }
      .pic img {
        max-width: 100%;
      }
      img {
        max-width: 40%;
        max-height: 550px;
      }
      .title {
        vertical-align: middle;
        text-align: center;
      }
      .title h1 { font-size: 100px; }
      .title p { font-size: 100px; }
      .quote {
        background: #eee;
        border-left: 10px solid #ccc;
        margin: 1.5em 10px;
        padding: 0.5em 10px;
        quotes: "\201C""\201D""\2018""\2019";
        font-style: italic;
      }
      .quote:before {
        color: #ccc;
        content: open-quote;
        font-size: 4em;
        line-height: 0.1em;
        margin-right: 0.25em;
        vertical-align: -0.4em;
      }
      .quote p {
        display: inline;
      }
      .warning {
        background-image: url("warning.png");
        background-size: 1.5em;
        background-repeat: no-repeat;
        padding-left: 2em;
      }
      .exercise {
        background-color: #eee;
        background-image: url("keyboard.png");
        background-size: 1.4em;
        background-repeat: no-repeat;
        background-position: 0.2em 0.2em;
        border: 2px dotted black;
      }
      .exercise::before {
        content: "Exercise";
        margin-left: 1.8em;
      }
      li p { line-height: 1.25em; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: title

# Open source recipes <br/> to build, ship and run <br/> production apps with Docker

---

class: title

Hi!

---

# About me

- Jérôme Petazzoni ([@jpetazzo](https://twitter.com/jpetazzo))

--

- Joined ~~Docker~~ dotCloud in 2010

--

- I wrote `dind` (Docker-in-Docker)

--

- And then a blog post explaining why you shouldn't use it

--

- That makes me a rather confused or confusing person

---

# About you

- I hope you use (or plan to use):

  - containers

--

  - Docker

--

  - Compose

--

  - ... in production

--

- I will pretend that you are interested in these things anyway

---

# About this talk

We are using Docker and Compose to run our app locally.

(Maybe it's architectured around microservices, maybe it isn't. It doesn't matter.)

Now, we want to do the following:

- deploy our app on a cluster,

- scale it to accommodate higher loads,

- centralize our logs,

- resist node failures.

---

class: pic

![Demo](demo.png)

---

# What do we want?

--

- Load balancing

--

- Scaling services

--

- Multi-node deployment

--

- Distributing container images
- Overlay networks

--

- Key/value store

--

- Host provisioning

---

class: title

This is all <br/> upside down

---

# Outline

- Best practices and pragmatism
- Host provisioning
- Key/value stores
- Overlay networks
- Distributing container images
- Deploying applications on Swarm
- Scaling services
- Load balancing
- Logging
- Speed of change in Docklandia

---

# Best practices and pragmatism

- Docker stance: "batteries included, but swappable"

- Docker provides defaults for almost everything

- You *will* want to change some of them, and that's OK

- In some cases, you *have to* make difficult decisions

  - network: overlay is great, but you need a key/value store
  - key/value stores are great, there are so many to choose from!
  - storage: stateful services *require* (or at least recommend strongly) a storage plugin
  - logging: if you have more than "just a little bit" of logs, some configuration is needed

- I'm going to be moderately opinionated; feel free to override/change anything

---

class: title

Host provisioning

---

# Docker Machine: the good parts

- Creates cloud instances for you

  (Abstracts differences between providers)

- Installs and configures Docker Engine (and optionally, Docker Swarm)

- Generates and deploys TLS certificates

- Integrate non-cloud resources (or provisioned differently) with the generic driver

---

# Docker Machine: to improve

- Out of the box, credentials are stored on a single machine (we will see how to fix this)

- Provisions one machine at a time (this will change in the future)

- Doesn't integrate (yet) with special constructs like auto-scaling groups

---

# Other options to provision Docker nodes

- Manual provisioning

  - install Docker Engine (use upstream packages!)
  
  - get.docker.com, test.docker.com

    ```bash
    aws ec2 run-instances --user-data '#include https://get.docker.com/' ...
    ```

  - setup TLS (!)

- Pre-existing configuration management system

---

# Example: provisioning a cluster with the generic driver

```bash
while read NODENAME IPADDR; do
    docker-machine create --driver generic \
      --engine-opt cluster-store=consul://localhost:8500 \
      --engine-opt cluster-advertise=eth0:2376 \
      --swarm --swarm-master \
      --swarm-discovery consul://localhost:8500  \
      --swarm-opt replication --swarm-opt advertise=$IPADDR:3376 \
      --generic-ssh-user ec2-user --generic-ip-address $IPADDR $NODENAME
done <<EOF
node1 11.2.3.4
node2 11.6.2.8
node3 11.9.2.6
node4 11.5.8.2
node5 11.0.3.6
EOF
```

<!-- -->

---

class: title

Key/value store

---

# Why do we want a key/value store? (1/2)

- Swarm cluster membership discovery

  - each node registers itself in Consul

  - Swarm managers learn about other nodes through this list

- Overlay network

  - IPAM (IP address management) to ensure unicity of IP addresses

  - keep track of container/node associations

  - remember: in the cloud, nobody can hear you broadcast

---

# Why do we want a key/value store? (2/2)

- Leader election

  - used by Swarm manager failover

  - Swarm itself doesn't run Raft/Serf/Paxos

- General all-purpose highly-available key/value store

  - hold critical information, e.g. Docker Machine certificates

  - example: ConsulFS


---

# Key/value stores: pick one!

- Zookeeper: old, sturdy, reconfiguration is painful

  - if you run into problems, others had them before you

- Etcd and Consul: new, shiny, better suited to "cloud" deployments

  - avoid them if you have a weird fetish about version 1.0
  
  - seriously though, ~~YOLO~~ 1.0 is overrated

---

# Key/value stores: how many, where?

- Up to 9 nodes → run the key/value store everywhere

- More than 10 nodes → run the key/value store on a subset (5-9 nodes)

  - with Etcd and Consul, you can run a "proxy" or "client agent" everywhere
    <br/>(but still need to pick a subset of "real servers")

- Remember: performance of ZAB, RAFT, etc. gets *worse* with more nodes!

---

# Key/value store: my personal choice for this demo

![Consul](consul.jpg) ![Pokeball](pokeball.png)

---

# Running Docker on Consul in Docker

- Of course we'll run Consul in a container
  <br/>(otherwise @jessfraz will kick me out of the Order Of The Containerati)

- There is an official Consul image on the Docker Hub now, and it's solid

- Each node will connect to Consul over `localhost`

- Each node runs the Consul agent

- The first N nodes will be servers

- The container will use *host networking* to simplify network discovery

- All nodes (except maybe one) must be given the address of at least another node

- Server nodes must be given boostrap options (I recommend `-bootstrap-expect N`)

---

# Example: starting a Consul cluster *in containers*

Assuming that your machines are `node[12345]`, run this from any of them:

```bash
IPADDR=$(ip a ls dev eth0 | sed -n 's,.*inet \(.*\)/.*,\1,p')
for N in 1 2 3 4 5; do
  ssh node$N -- docker run -d --restart=always --name consul_node$N \
                -e CONSUL_BIND_INTERFACE=eth0 --net host consul \
                agent -server -retry-join $IPADDR -bootstrap-expect 5 \
                `-ui -client 0.0.0.0`
done
```

(`-ui -client 0.0.0.0` is great for debugging, less so for production ☺)

Pro tip: setup DNS round robin records for your server nodes, and use that
to get other nodes to join the cluster!

---

# Overlay networks: simple multi-host networking

- Allows creation of private networks for groups of containers (~VLANs)

- Under the hood: VXLAN + key/value store

- Encapsulates Ethernet in plain UDP packets (works *everywhere*)

- Docker also allows to associate scoped DNS records with containers

- Containers can be in multiple networks, and can dynamically be connected/disconnected

- Overlay networks are integrated with Compose

---

# Overlay networks: example with the Docker CLI

```bash
docker network create myapp
docker run -d --net myapp --name myapp-db --net-alias db redis
docker run -d --net myapp --name myapp-web1 --net-alias www nginx
docker run -d --net myapp --name myapp-web2 --net-alias www nginx
docker run -d --net myapp --name myapp-web3 --net-alias www nginx
```

For any container started in network `myapp`:
- myapp-db and db resolve to the redis container
- www resolves to myapp-web1, 2, and 3

Containers can't directly communicate with (or resolve names and addresses of) containers in different networks.

Containers can be in multiple networks (and enable communication between them).

---

# Overlay networks: example with Compose

```yaml
networks:
  public:
  private:

services:
  loadbalancer:
    image: ...
    networks:
      public:
        aliases: [ www ]
      private:
  www:
    image: ...
    networks:
      private:
```

The `loadbalancer` service enables communication with `www` from the `public` network.

---

# Distributing container images: why do we need this?

- When developing your application, your Compose file probably has this:
  ```yaml
    www:
      build: www
      ...
  ```

- Or, if your application is simple enough to have only one service, maybe you do this:
  ```bash
  docker build -t www .
  ```

- The resulting image(s) must be deployed on all your nodes
  <br/>(or at least the nodes on which that specific container should run)

- Docker might eventually have crazy peer-to-peer image distribution

- Meanwhile, it's easier to use a registry

---

# Distributing container images: what are our options?

- SAAS (e.g.: [Docker Hub](https://hub.docker.com/))

  - zero work
  - free (for public images) / cheap (for private images)

- Self-hosted, commercial (e.g.: [Docker Trusted Registry](https://www.docker.com/products/docker-trusted-registry))

  - a bit of work
  - a bit of money (storage and hosting costs; licensing)

- Self-hosted, open-source (e.g.: `docker run` [`registry:2`](https://hub.docker.com/r/library/registry/))

  - a bit of money (storage and hosting costs)
  - some work (to set it up)
  - more work (for identification, authentification, workflow...)

---

# Distributing container images: what you need to know

- Docker *requires* TLS to the registry

  - except with the `insecure-registry` daemon flag
    <br/>(requires reconfiguration + restart)

  - except if the registry is on `localhost`

  - or just use Let's Encrypt

- If you are in `$CLOUD`, use its object store

- If you use external storage, you can run one registry instance per host
  <br/>(and use `localhost` as your registry)

---

# Cheap registry to get started

```yaml
version: "2"

services:
  backend:
    image: registry:2
  frontend:
    image: jpetazzo/hamba
    command: 5000 backend:5000
    ports:
      - "127.0.0.1:5000:5000"
    depends_on:
      - backend
```

Scale the `frontend` service to one instance per node.

Use `localhost:5000` as your registry.

---

class: title

Checkpoint

---

# What do we have?

- Docker Engine nodes capable of running containers

- Management of those nodes through a single API endpoint with Swarm

- Overlay networks allowing communication between containers across nodes

- Internal image distribution with a secure (but non-HA) registry

---

# What do we need?

- Deploy to the cluster using our Compose file

- Scale services across multiple nodes

- Load balance traffic

- Centralized logging

(And more, but that'd be a good start!)

---

# `docker-compose up` : on a single node

- Services declared with an `image` instruction are pulled (if necessary)

- Services declared with a `build` instruction are built (if necessary)

- Containers are created and started

---

# `docker-compose up` : on a cluster

- Services declared with an `image` instruction can be pulled similarly

- Services declared with a `build` instruction:

  - are built on a single node

  - can therefore only run on that node

---

# `docker-compose up` on a cluster

We need to get rid of `build` instructions and replace them with `image` instead:

(1) Build (using `docker-compose build`)

(2) Tag resulting images with unique tag (timestamp, commit hash...)

(3) Push those images to a registry

(4) Generate a new Compose file where each `build` is replaced with an `image` reference

(5) `docker-compose up` with that file

---

# Compose file, before

```yaml
services:
  rng:
    build: rng

  hasher:
    build: hasher

  webui:
    build: webui
    ports:
    - "80:80"

  redis:
    image: redis

  worker:
    build: worker
```

---

# Copmose file, after

```yaml
services:
  rng:
    image: localhost:5000/dockercoins_rng:123456789

  hasher:
    image: localhost:5000/dockercoins_hasher:123456789

  webui:
    image: localhost:5000/dockercoins_webui:123456789
    ports:
    - "80:80"

  redis:
    image: redis

  worker:
    image: localhost:5000/dockercoins_worker:123456789
```

---

# Deploying on Swarm: results 

- Our application is running on multiple nodes
 
  (Depending on our Swarm placement policy)

- Communication happens transparently using overlay networks

- We can still use the tools we know (and maybe love):

  - docker exec
  - docker inspect
  - docker stats
  - docker top
  - implicit co-scheduling (`--net container:…`, `--volumes-from`)

---

# Scaling services

- Not all services are equally easy to scale

- Stateless is easier than stateful (obviously!)

- Some services are more stateful than others

- Let's break down the stateful/stateless dichotomy!

---

# Stateless workers

- They don't accept network traffic

- They run continuously ...

- ... or at regular intervals ...

- ... or pull tasks from message queues

- To scale them, just start more copies

  ```bash
  docker-compose scale worker=10
  ```

---

# Stateless services

- They accept network traffic

- They don't persist any state between requests

- Each request could be serviced by a fresh container

- To scale them, just start more copies

- DNS round robin will load balance the traffic (unfairly)

  (i.e. you will want a load balancer anyway)

---

# Services with ephemeral or local state

- They accept network traffic

- They persist state between requests (ideally, it's just caching)

- Each request could be serviced by a fresh container, but performance would suck

- To scale them, just start more copies

- Put a load balancer in front

- Use network name scoping to make it transparent

---

# Transparent network plumbing with Swarm

```yaml
networks:
  public:
  private:

services:
  loadbalancer:
    image: ...
    networks:
      public:
        aliases: [ www ]
      private:
  www:
    image: ...
    networks:
      private:
```

(See [this script](https://github.com/jpetazzo/orchestration-workshop/blob/master/bin/add-load-balancer-v2.py) for the detailed version of this pattern.)

---

# Data stores with built-in symetric replication

- Example: Consul, Etcd, Riak

- You can connect to any node (requests are routed by the service or client-side logic)

- Nodes can be added at will (and removed under certain conditions)

- Those systems generally require awareness of their IP address

- Port mapping is possible, but makes things complex; use overlay networks

---

# Data stores with asymetric replication

- Example: PostgreSQL, MySQL

- You connect to the primary or leader (unless you want read-only operation)

- Extra logic is required for leader election, health checking, follower promotion

- See e.g. [zalando/patroni](https://github.com/zalando/patroni) (HA PostgreSQL)

---

# Data stores without native replication

- Systems where high availability is traditionally achieved with redundant hardware

- Solution 1: put those containers on redundant hardware

- Solution 2: use HA container storage like Flocker, PortWorx, BlockBridge, etc.

---

# Keeping your sanity

- Stateful services are not trivial to operate

- Do you want to run this yourself?

--

- By increasing difficulty:

--

  - getting someone else to run your data store

--

  - running your data store in containers when you know containers

--

  - running your data store outside of containers

--

  - running your data store in containers when you don't know containers

---

# When to use Docker for your data stores?

- Docker gives you a huge ROI for fast-changing services

  (Stuff that change a lot and are complex to build)

- Leverage Docker for those services first

- In dev environments: put data stores in containers early (no risk)

- In prod environments: abtract external services with ambassadors

- Put production databases in containers once you are ready

  (You will know when you are ☺)

---

# Logging

- Docker has *logging drivers*

- You can set the logging driver per Engine, or per container

- You can run your logging stack in containers, because *why not*

---

# Example: running ELK on Docker

```yaml
elasticsearch:
  image: elasticsearch

logstash:
  image: logstash
  command: |
    -e 'input { gelf { } }
        filter { ... }
        output { elasticsearch { hosts => ["elasticsearch:9200"] } }'
  ports:
    - "127.0.0.1:12201:12201/udp"

kibana:
  image: kibana
  ports:
    - "5601:5601"
  environment:
    ELASTICSEARCH_URL: http://elasticsearch:9200
```

---

# Extra details about this ELK stack ...

- You want to scale ElasticSearch

- Scale logstash to have one instance per host

  (UDP is unreliable, but UDP over localhost is significantly less bad)

- If you have huge bursts and don't want to lose logs, add a Redis or Kafka queue

  (Yes, your logging stack suddenly became way more complicated, what did you expect?)

---

# What about high availability?

- The Swarm manager itself has good redundancy

- Container rescheduling is here, but needs improvement

  (Work in progress, with significant improvements in Swarm 1.1, 1.2)

---
 
# Speed of change in Docklandia

- Docker moves *fast*, e.g.:

  - Engine 1.9 (November 2015) introduces overlay networks

  - Engine 1.10 (February 2016) introduces embedded DNS, network aliases

  - Engine 1.11 (April 2016) introduces round-robin DNS load balancing

  - Engine 1.12 will continue on this trajectory

- Features go from "experimental and buggy" to "stable at scale" very quickly

- Things are likely to change *SOON*

  (Like, you know, DockerCon...)

---

# Would you like to know more?

- All the examples shown here are drawn from my orchestration workshop

  (Slides, examples, scripts are all publicly availably)

- Repo: https://github.com/jpetazzo/orchestration-workshop/

- Slides: http://container.training/

- I gave an earlier version of that talk at CRAFT in Budapest

  (a recording is available)

---

class: title

# Thanks! <br/> Questions?

## [@jpetazzo](https://twitter.com/jpetazzo) <br/> [@docker](https://twitter.com/docker)

    </textarea>
    <script src="remark-0.13.min.js" type="text/javascript"></script>
    <script src="/assets/remark-0.13.min.js" type="text/javascript"></script>
    <script type="text/javascript">
      var slideshow = remark.create({
        countIncrementalSlides: false,
        ratio: '16:9',
        highlightSpans: true
      });
    </script>
  </body>
</html>
